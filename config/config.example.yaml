use_prompts_yaml: false

llm:
  provider: "openrouter"
  api_base: "https://openrouter.ai/api/v1"
  api_key: "YOUR_API_KEY_HERE"
  model: "openrouter/optimus-alpha"

# llm:
#   provider: "litellm"
#   api_base: "http://your-litellm-endpoint"
#   api_key: "YOUR_API_KEY_HERE"
#   model: "claude-3-7-load-balance"
#   temperature: 0.7
#   max_tokens: 20000
